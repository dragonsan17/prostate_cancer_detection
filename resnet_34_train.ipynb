{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet_34_train.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0l6GZPWqv_30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git\n",
        "!pip install -q torchviz\n",
        "!pip install albumentations==0.4.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S99Qm6WnwpBn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import skimage.io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import PIL.Image\n",
        "from pylab import rcParams\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler, RandomSampler, SequentialSampler\n",
        "from warmup_scheduler import GradualWarmupScheduler\n",
        "import albumentations\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from torchvision.models import resnet34"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bz5QQXcgyJjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = '../input/prostate-cancer-grade-assessment/'\n",
        "df_train = pd.read_csv(data_path + 'train.csv')\n",
        "image_path = '../input/panda_data/'\n",
        "fold = 0\n",
        "num_workers = 4\n",
        "init_lr = 3e-5\n",
        "warmup_factor = 3\n",
        "warmup_epo = 1\n",
        "n_epochs = 40\n",
        "batch_size = 8\n",
        "num_folds = 5\n",
        "device = torch.device('cuda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMP5LJe9ybXR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "skf = StratifiedKFold(num_folds, shuffle=True, random_state=42)\n",
        "df_train['fold'] = -1\n",
        "for i, (train_idx, valid_idx) in enumerate(skf.split(df_train, df_train['isup_grade'])):\n",
        "    df_train.loc[valid_idx, 'fold'] = i\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09bRGcrTyiS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Data_Loader(Dataset):\n",
        "    def __init__(self,\n",
        "                 df,\n",
        "                 rand=False,\n",
        "                 transform=None,\n",
        "                ):\n",
        "\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.rand = rand\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.df.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        row = self.df.iloc[index]\n",
        "        img_id = row.image_id\n",
        "        folder_idx = row.folder_idx\n",
        "        if(folder_idx==0 or folder_idx == 5):\n",
        "            images = plt.imread((image_path + str(img_id) + '.png'))\n",
        "        else:\n",
        "            images = plt.imread((image_path + str(img_id) + '.png'))\n",
        "        images = cv2.cvtColor(images, cv2.COLOR_BGRA2BGR)\n",
        "        images = 1 - images\n",
        "        images = images.astype(np.float32)\n",
        "        images = images.transpose(2, 0, 1)\n",
        "\n",
        "        label = np.zeros(5).astype(np.float32)\n",
        "        label[:row.isup_grade] = 1.\n",
        "        return torch.tensor(images), torch.tensor(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0GNORXryv3a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_show = Data_Loader(df_train)\n",
        "rcParams['figure.figsize'] = 20,10\n",
        "for i in range(2):\n",
        "    f, axarr = plt.subplots(1,5)\n",
        "    for p in range(5):\n",
        "        idx = np.random.randint(0, len(dataset_show))\n",
        "        img, label = dataset_show[idx]\n",
        "        label = label.numpy().astype(int)\n",
        "        axarr[p].imshow(1. - img.transpose(0, 1).transpose(1,2).squeeze())\n",
        "        axarr[p].set_title('i_sup grade : ' + str(np.sum(label)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBhQm8Gfy3EK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "class ResNetDetector(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResNetDetector, self).__init__()\n",
        "\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        self.dense_1 = nn.Linear(512, 5)\n",
        "        self.resnet = resnet34(pretrained=True)\n",
        "        self.resnet = nn.Sequential(*list(self.resnet.children())[:-1])\n",
        "        \n",
        "    def forward(self, img):\n",
        "        feat = self.resnet(img).squeeze()\n",
        "\n",
        "        isup_logit = self.dense_1(feat)\n",
        "        return isup_logit\n",
        "\n",
        "model = ResNetDetector()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftuFNU7ay5HC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def engine(train_loader, valid_loader, optimizer):\n",
        "    train_loss = []\n",
        "    val_loss = []\n",
        "    PREDS = []\n",
        "    TARGETS = []\n",
        "\n",
        "    model.train()\n",
        "    train_loss = []\n",
        "    bar = tqdm(train_loader)\n",
        "    for (data, target) in bar:\n",
        "        \n",
        "        data, target = data.to(device), target.to(device)\n",
        "        loss_func = criterion\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(data)\n",
        "        loss = loss_func(logits, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_np = loss.detach().cpu().numpy()\n",
        "        train_loss.append(loss_np)\n",
        "        smooth_loss = sum(train_loss[-100:]) / min(len(train_loss), 100)\n",
        "        total_loss = sum(train_loss) / max(len(train_loss), 1)\n",
        "        bar.set_description('loss: %.5f, smth: %.5f, total: %.5f' % (loss_np, smooth_loss, total_loss))\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for (data, target) in tqdm(loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            logits = model(data)\n",
        "\n",
        "            loss = criterion(logits, target)\n",
        "\n",
        "            pred = logits.sigmoid().sum(1).detach().round()\n",
        "            PREDS.append(pred)\n",
        "            TARGETS.append(target.sum(1))\n",
        "            val_loss.append(loss.detach().cpu().numpy())\n",
        "        val_loss = np.mean(val_loss)\n",
        "\n",
        "    PREDS = torch.cat(PREDS).cpu().numpy()\n",
        "    TARGETS = torch.cat(TARGETS).cpu().numpy()\n",
        "    acc = (PREDS == TARGETS).mean() * 100.\n",
        "    \n",
        "    qwk = cohen_kappa_score(PREDS, TARGETS, weights='quadratic')\n",
        "    print('qwk', qwk)\n",
        "\n",
        "    return train_loss, val_loss, acc, qwk "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqrcjbUvy7VF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_idx = np.where((df_train['fold'] != fold))[0]\n",
        "valid_idx = np.where((df_train['fold'] == fold))[0]\n",
        "\n",
        "df_this  = df_train.loc[train_idx]\n",
        "df_valid = df_train.loc[valid_idx]\n",
        "\n",
        "dataset_train = Data_Loader(df_this)\n",
        "dataset_valid = Data_Loader(df_valid)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, sampler=RandomSampler(dataset_train), num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset_valid, batch_size=batch_size, sampler=SequentialSampler(dataset_valid), num_workers=num_workers)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=init_lr/warmup_factor)\n",
        "scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, n_epochs-warmup_epo)\n",
        "scheduler = GradualWarmupScheduler(optimizer, multiplier=warmup_factor, total_epoch=warmup_epo, after_scheduler=scheduler_cosine)\n",
        "\n",
        "print(len(dataset_train), len(dataset_valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoA5KnCWy_Xa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "qwk_max = 0.\n",
        "for epoch in range(1, n_epochs+1):\n",
        "    print(time.ctime(), 'Epoch:', epoch)\n",
        "    scheduler.step(epoch-1)\n",
        "    train_loss, val_loss, acc, qwk = engine(train_loader, valid_loader, optimizer)\n",
        "    content = time.ctime() + ' ' + f'Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, train loss: {np.mean(train_loss):.5f}, val loss: {np.mean(val_loss):.5f}, acc: {(acc):.5f}, qwk: {(qwk):.5f}'\n",
        "    print(content)\n",
        "    with open(f'log_{kernel_type}.txt', 'a') as appender:\n",
        "        appender.write(content + '\\n')\n",
        "    if qwk > qwk_max:\n",
        "        torch.save(model.state_dict(), f'{kernel_type}.pth')\n",
        "        qwk_max = qwk\n",
        "torch.save(model.state_dict(), os.path.join(f'{kernel_type}_final_fold{fold}.pth'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}